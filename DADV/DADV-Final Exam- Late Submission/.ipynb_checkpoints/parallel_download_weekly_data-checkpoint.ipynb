{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exact-washington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipynb in c:\\users\\ranjith\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "extraordinary-recovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: import_ipynb in c:\\users\\ranjith\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "printable-tooth",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Driver [C:\\Users\\Ranjith\\.wdm\\drivers\\chromedriver\\win32\\90.0.4430.24\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505\n"
     ]
    }
   ],
   "source": [
    "#importing necessary libraries to scrap data.\n",
    "#for scraping yusing beatiful soup\n",
    "#For importing ipynb using import_ipynb\n",
    "#for scraping from website, using chome driver to convert that data to our convenitent form.\n",
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import io\n",
    "import gzip\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from multiprocessing import Pool\n",
    "import import_ipynb\n",
    "import pandas as pd\n",
    "from ipynb.fs.full.scraping_weekly_data import scraping_weekly_data\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "driver.get(url)\n",
    "\n",
    "symbols = list()\n",
    "symbols_GICC = dict()\n",
    "\n",
    "#This html code is the refernece of the data at history data on webpage.\n",
    "table = \"/html/body/div[3]/div[3]/div[5]/div[1]/table[1]\"\n",
    "table = driver.find_element_by_xpath(table)\n",
    "elements = table.find_elements_by_tag_name(\"tr\")[1:]\n",
    "\n",
    "#Storing all the rows in a list set, to print them using funtion in scraping file.\n",
    "for row in elements:\n",
    "    data = [data.text for data in row.find_elements_by_tag_name(\"td\")]\n",
    "    symbols.append(data[0])\n",
    "    symbols_GICC[data[0]] = data[3]\n",
    "\n",
    "print(len(symbols_GICC))\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Pool(30)\n",
    "    df_daily_list = p.map(scraping_weekly_data, symbols)\n",
    "    p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-xerox",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
